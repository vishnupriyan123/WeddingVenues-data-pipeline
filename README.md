# 🤖 Wedding Venue Data Pipeline — Automated Scraping, Cleaning & AI Visualization

A fully automated data pipeline for scraping, cleaning, enriching, and visualizing wedding venue data from public listings — built with Python, Selenium, and AI-powered Streamlit tools.

---

🚀 Features

1️⃣ Data Pipeline Automation
	•	Web scraper using Selenium + ChromeDriver
	•	Extracts listings from Hitched.co.uk (supports pagination & dynamic content)
	•	Fully scheduled with GitHub Actions using CRON at 4:30 AM UTC (10 AM IST)
	•	Uploads clean JSON/CSV + logs as GitHub Action artifacts

2️⃣ Data Cleaning & Standardization
	•	Cleans missing or invalid values with Pandas
	•	Parses prices, review counts, capacity fields
	•	Saves both:
	•	latest version for dashboards
	•	timestamped snapshots for historical tracking

3️⃣ Logging & Traceability
	•	Scraper and cleaner each write to:
	•	scraper_log.txt
	•	cleaner_log.txt
	•	Logs number of rows scraped/cleaned and timestamps
	•	Both logs are archived and downloadable via GitHub Actions artifacts

4️⃣ Visualization & Analysis
	•	📊 analyzer.py: static charts with Matplotlib/Seaborn
	•	🤖 ai-data-viz.py: AI-driven dashboard via Streamlit + Together AI
	•	Ask questions like “Show average price by location”
	•	Charts are generated by LLMs and downloadable as PNGs
	•	Multiple model support (Llama 3, Qwen, DeepSeek, etc.)

5️⃣ Version Control & Modularity
	•	.gitignore configured to keep repo clean
	•	Folder structure:
	•	/main/data/raw: Raw JSON (latest + timestamped)
	•	/main/data/processed: Cleaned CSV (latest + timestamped)
	•	/main/logs: Log files
	•	/main/plots: Saved visuals
	•	Modular scripts for scraping, cleaning, analyzing, AI dashboard

---

## 📁 Project Structure

```bash
WeddingVenues-data-pipeline/
├── main/
│   ├── data/
│   │   ├── raw/              # Scraped JSON
│   │   └── processed/        # Cleaned CSV
│   ├── logs/                 # Run logs (scraper/cleaner)
│   ├── plots/                # Static PNG charts
│   ├── scraper.py            # Web scraper (Selenium)
│   ├── cleaner.py            # Pandas cleaner
│   ├── analyzer.py           # Static chart generator
│   └── ai-data-viz.py        # AI-powered Streamlit UI
├── .github/workflows/
│   └── pipeline.yml          # GitHub Actions daily workflow
├── .gitignore
├── requirements.txt
└── README.md


🚀 How to Run

1. Setup

```bash

git clone https://github.com/vishnupriyan123/WeddingVenues-data-pipeline.git
cd WeddingVenues-data-pipeline
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

2.  Run Scraper & Cleaner

python scripts/scraper.py
python scripts/cleaner.py

3️⃣ Visualize the Data

📊 Static Charts


```bash

python scripts/analyzer.py

🤖 AI-Powered Streamlit App

Supports Together AI & E2B backends (API keys required)

🔐 Requirements
	•	Get a Together AI API Key
	•	Get an E2B API Key

▶️ Run the app:

```bash

streamlit run scripts/ai-data-viz.py


🧠 Ask questions like: (refer the column names and use the same column names)
	•	“plot average price_numeric by location”
	•	“Plot venue rating vs price”

✨ Features:
	•	AI suggests chart type & titles
	•	Multiple LLMs supported
	•	Download charts as PNGs

⸻

🔁 GitHub Actions: Daily Automation
	•	Scraper + Cleaner runs daily at 4:30 AM UTC
	•	Uploads artifacts:
	•	hitched_venues.json / hitched_venues_<date>.json
	•	cleaned_venues.csv / cleaned_venues_<date>.csv
	•	scraper_log.txt, cleaner_log.txt
	•	Commit latest cleaned_venues.csv to GitHub (timestamped files excluded via .gitignore)

⸻

🛡️ GDPR & Legal Notes

✅ This project is GDPR-compliant:
	•	Only scrapes public business listings (no personal data)
	•	Does not collect or store user-identifiable information
	•	Logs and artifacts are for internal analysis only
	•	Add-on disclaimer in code:
“Scraper processes publicly available data only. No personal data is collected or stored.”

⸻

🧠 Tech Stack
	•	Python 3.10
	•	Selenium (ChromeDriver)
	•	Pandas
	•	Matplotlib / Seaborn
	•	Streamlit
	•	Together AI + E2B (LLMs)
	•	GitHub Actions (CI/CD)
	•	CRON (Automation)

⸻

✅ Roadmap & What’s Next
	•	Daily automation with GitHub Actions
	•	Timestamped logging and snapshots
	•	AI-powered natural language querying
	•	Versioned clean dataset with GitHub commits
	•	💾 Add PostgreSQL or SQLite DB integration
	•	📈 Dashboard for profile completeness & lead scoring
	•	🌐 Scrape other regions (multi-region support)

⸻

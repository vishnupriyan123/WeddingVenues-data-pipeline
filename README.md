# ğŸ¤– Wedding Venues Data Pipeline â€” Automated Scraping, Cleaning & AI Visualization

A fully automated data pipeline for scraping, cleaning, enriching, and visualizing wedding venue data from public listings â€” built with Python, Selenium, and AI-powered Streamlit tools.

---

## ğŸš€ Features

### 1ï¸âƒ£ Automated Data Pipeline
- Scrapes wedding venue listings from **Hitched.co.uk** using **Selenium + ChromeDriver**
- Handles **pagination** and **dynamic content** seamlessly
- Runs daily at **4:30 AM UTC / 10:00 AM IST** via **GitHub Actions** (CRON-based)
- Uploads cleaned data (JSON + CSV) and logs as downloadable **GitHub Artifacts**

### 2ï¸âƒ£ Data Cleaning & Standardization
- Cleans missing or inconsistent values using **Pandas**
- Parses prices, review counts, and capacity fields into standardized formats
- Stores:
  - `cleaned_venues.csv`: latest version for dashboards
  - `cleaned_venues_YYYYMMDD.csv`: timestamped for historical reference

### 3ï¸âƒ£ Logging & Traceability
- Generates detailed logs for both scraper and cleaner:
  - `scraper_log.txt`
  - `cleaner_log.txt`
- Includes timestamp, row count, and error handling info
- Logs are archived and uploaded as **workflow artifacts**

### 4ï¸âƒ£ Visualization & AI-Powered Analysis
- ğŸ“Š `analyzer.py`: Static charts with **Matplotlib**/**Seaborn**
- ğŸ¤– `ai-data-viz.py`: Natural language dashboard built with **Streamlit** and **Together AI**
  - Ask questions like _"Show average price by location"_
  - Visualizations generated by LLMs (supports **LLaMA 3**, **Qwen**, **DeepSeek**, etc.)
  - All charts are downloadable as PNG

### 5ï¸âƒ£ Modularity & Version Control
- Clean and modular project structure
- GitHub-managed `.gitignore` excludes environment, logs, images, and temporary files
- Organized folders:
  - `main/data/raw/`: Scraped JSON (latest + historical)
  - `main/data/processed/`: Cleaned CSV (latest + historical)
  - `main/logs/`: Run logs
  - `main/plots/`: Output charts
- All code split into modular scripts:
  - `scraper.py`, `cleaner.py`, `analyzer.py`, `ai-data-viz.py`
---

## ğŸ“ Project Structure

```bash
WeddingVenues-data-pipeline/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/              # Scraped JSON
â”‚   â”‚   â””â”€â”€ processed/        # Cleaned CSV
â”‚   â”œâ”€â”€ logs/                 # Run logs (scraper/cleaner)
â”‚   â”œâ”€â”€ plots/                # Static PNG charts
â”‚   â”œâ”€â”€ scraper.py            # Web scraper (Selenium)
â”‚   â”œâ”€â”€ cleaner.py            # Pandas cleaner
â”‚   â”œâ”€â”€ analyzer.py           # Static chart generator
â”‚   â””â”€â”€ ai-data-viz.py        # AI-powered Streamlit UI
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ pipeline.yml          # GitHub Actions daily workflow
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

ğŸš€ How to Run

1. Setup

```bash

git clone https://github.com/vishnupriyan123/WeddingVenues-data-pipeline.git
cd WeddingVenues-data-pipeline
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
2.  Run Scraper & Cleaner

python scripts/scraper.py
python scripts/cleaner.py

3ï¸âƒ£ Visualize the Data

ğŸ“Š Static Charts


```bash

python scripts/analyzer.py
```
ğŸ¤– AI-Powered Streamlit App

Supports Together AI & E2B backends (API keys required)

ğŸ” Requirements
	â€¢	Get a Together AI API Key
	â€¢	Get an E2B API Key

â–¶ï¸ Run the app:

```bash

streamlit run scripts/ai-data-viz.py
```

ğŸ§  Ask questions like: (refer the column names and use the same column names)
	â€¢	â€œplot average price_numeric by locationâ€
	â€¢	â€œPlot venue rating vs priceâ€

âœ¨ Features:
	â€¢	AI suggests chart type & titles
	â€¢	Multiple LLMs supported
	â€¢	Download charts as PNGs

â¸»

ğŸ” GitHub Actions: Daily Automation
	â€¢	Scraper + Cleaner runs daily at 4:30 AM UTC
	â€¢	Uploads artifacts:
	â€¢	hitched_venues.json / hitched_venues_<date>.json
	â€¢	cleaned_venues.csv / cleaned_venues_<date>.csv
	â€¢	scraper_log.txt, cleaner_log.txt
	â€¢	Commit latest cleaned_venues.csv to GitHub (timestamped files excluded via .gitignore)

â¸»

ğŸ›¡ï¸ GDPR & Legal Notes

âœ… This project is GDPR-compliant:
	â€¢	Only scrapes public business listings (no personal data)
	â€¢	Does not collect or store user-identifiable information
	â€¢	Logs and artifacts are for internal analysis only

â¸»

ğŸ§  Tech Stack
	â€¢	Python 3.10
	â€¢	Selenium (ChromeDriver)
	â€¢	Pandas
	â€¢	Matplotlib / Seaborn
	â€¢	Streamlit
	â€¢	Together AI + E2B (LLMs)
	â€¢	GitHub Actions (CI/CD)
	â€¢	CRON (Automation)

â¸»

âœ… Roadmap & Whatâ€™s Next
	â€¢	Daily automation with GitHub Actions
	â€¢	Timestamped logging and snapshots
	â€¢	AI-powered natural language querying
	â€¢	Versioned clean dataset with GitHub commits
	â€¢	ğŸ’¾ Add PostgreSQL or SQLite DB integration
	â€¢	ğŸ“ˆ Dashboard for profile completeness & lead scoring
	â€¢	ğŸŒ Scrape other regions (multi-region support)

â¸»

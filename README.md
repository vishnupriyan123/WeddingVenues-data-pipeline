# 🤖 Wedding Venues Data Pipeline — Automated Scraping, Cleaning & AI Visualization

A fully automated data pipeline for scraping, cleaning, enriching, and visualizing wedding venue data from public listings — built with Python, Selenium, and AI-powered Streamlit tools.

---

## 🚀 Features

### 1️⃣ Automated Data Pipeline
- Scrapes wedding venue listings from **Hitched.co.uk** using **Selenium + ChromeDriver**
- Handles **pagination** and **dynamic content** seamlessly
- Runs daily at **4:30 AM UTC / 10:00 AM IST** via **GitHub Actions** (CRON-based)
- Uploads cleaned data (JSON + CSV) and logs as downloadable **GitHub Artifacts**

### 2️⃣ Data Cleaning & Standardization
- Cleans missing or inconsistent values using **Pandas**
- Parses prices, review counts, and capacity fields into standardized formats
- Stores:
  - `cleaned_venues.csv`: latest version for dashboards
  - `cleaned_venues_YYYYMMDD.csv`: timestamped for historical reference

### 3️⃣ Logging & Traceability
- Generates detailed logs for both scraper and cleaner:
  - `scraper_log.txt`
  - `cleaner_log.txt`
- Includes timestamp, row count, and error handling info
- Logs are archived and uploaded as **workflow artifacts**

### 4️⃣ Visualization & AI-Powered Analysis
- 📊 `analyzer.py`: Static charts with **Matplotlib**/**Seaborn**
- 🤖 `ai-data-viz.py`: Natural language dashboard built with **Streamlit** and **Together AI**
  - Ask questions like _"Show average price by location"_
  - Visualizations generated by LLMs (supports **LLaMA 3**, **Qwen**, **DeepSeek**, etc.)
  - All charts are downloadable as PNG

### 5️⃣ Modularity & Version Control
- Clean and modular project structure
- GitHub-managed `.gitignore` excludes environment, logs, images, and temporary files
- Organized folders:
  - `main/data/raw/`: Scraped JSON (latest + historical)
  - `main/data/processed/`: Cleaned CSV (latest + historical)
  - `main/logs/`: Run logs
  - `main/plots/`: Output charts
- All code split into modular scripts:
  - `scraper.py`, `cleaner.py`, `analyzer.py`, `ai-data-viz.py`
---

## 📁 Project Structure

```bash
WeddingVenues-data-pipeline/
├── main/
│   ├── data/
│   │   ├── raw/              # Scraped JSON
│   │   └── processed/        # Cleaned CSV
│   ├── logs/                 # Run logs (scraper/cleaner)
│   ├── plots/                # Static PNG charts
│   ├── scraper.py            # Web scraper (Selenium)
│   ├── cleaner.py            # Pandas cleaner
│   ├── analyzer.py           # Static chart generator
│   └── ai-data-viz.py        # AI-powered Streamlit UI
├── .github/workflows/
│   └── pipeline.yml          # GitHub Actions daily workflow
├── .gitignore
├── requirements.txt
└── README.md
```

🚀 How to Run

1. Setup

```bash

git clone https://github.com/vishnupriyan123/WeddingVenues-data-pipeline.git
cd WeddingVenues-data-pipeline
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
2.  Run Scraper & Cleaner

python scripts/scraper.py
python scripts/cleaner.py

3️⃣ Visualize the Data

📊 Static Charts


```bash

python scripts/analyzer.py
```
🤖 AI-Powered Streamlit App

Supports Together AI & E2B backends (API keys required)

🔐 Requirements
	•	Get a Together AI API Key
	•	Get an E2B API Key

▶️ Run the app:

```bash

streamlit run scripts/ai-data-viz.py
```

🧠 Ask questions like: (refer the column names and use the same column names)
	•	“plot average price_numeric by location”
	•	“Plot venue rating vs price”

✨ Features:
	•	AI suggests chart type & titles
	•	Multiple LLMs supported
	•	Download charts as PNGs

⸻

🔁 GitHub Actions: Daily Automation
	•	Scraper + Cleaner runs daily at 4:30 AM UTC
	•	Uploads artifacts:
	•	hitched_venues.json / hitched_venues_<date>.json
	•	cleaned_venues.csv / cleaned_venues_<date>.csv
	•	scraper_log.txt, cleaner_log.txt
	•	Commit latest cleaned_venues.csv to GitHub (timestamped files excluded via .gitignore)

⸻

🛡️ GDPR & Legal Notes

✅ This project is GDPR-compliant:
	•	Only scrapes public business listings (no personal data)
	•	Does not collect or store user-identifiable information
	•	Logs and artifacts are for internal analysis only

⸻

🧠 Tech Stack
	•	Python 3.10
	•	Selenium (ChromeDriver)
	•	Pandas
	•	Matplotlib / Seaborn
	•	Streamlit
	•	Together AI + E2B (LLMs)
	•	GitHub Actions (CI/CD)
	•	CRON (Automation)

⸻

✅ Roadmap & What’s Next
	•	Daily automation with GitHub Actions
	•	Timestamped logging and snapshots
	•	AI-powered natural language querying
	•	Versioned clean dataset with GitHub commits
	•	💾 Add PostgreSQL or SQLite DB integration
	•	📈 Dashboard for profile completeness & lead scoring
	•	🌐 Scrape other regions (multi-region support)

⸻
